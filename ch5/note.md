# 第 5 章：优化程序性能

编写高效程序需要做到以下几点：
- 我们必须选择一组适当的算法和数据结构
- 我们必须编写出编译器能够有效优化以转换成高效可执行代码的源代码
- 针对处理运算量特别大的计算，将一个任务分成多个部分，这些部分可以在多核和多处理器的某种组合上并行地计算

程序优化：
- 消除不必要的工作，让代码尽可能有效地执行所期望的任务。这包括消除不必要的函数调用、条件测试和内存引用。这些优化不依赖于目标机器的任何具体属性
- 利用处理器提供的指令级并行能力，同时执行多条指令

## 5.1 优化编译器的能力和局限性

GCC 向用户提供了一些对它们所使用的优化的控制，例如指定优化级别（-Og -O1 -O2 等）

编译器必须很小心地对程序只使用*安全*的优化，也就是说对于程序可能遇到的所有可能情况，在 C 语言标准提供的保证之下，优化后得到的程序和未优化的版本有一样的行为。因此程序中存在一些妨碍优化的因素：
- 程序中不同的指针可能会指向同一个内存位置（内存别名使用）
- 函数调用可能存在副作用

## 5.2 表示程序性能

引入度量标准*每元素的周期数*（Cycles Per Element, CPE），作为一种表示程序性能并指导我们改进代码的方法
- CPE：运行一个过程所需的时间可以用一个常数加上一个与被处理元素个数成正比的因子来描述，这个因子（也就是线段的斜率）称为 CPE

## 5.3 程序示例

给出一段初始代码：

```c
// 定义向量结构：头信息+指定长度的数组（len长度的data_t类型对象数组） 
typedef struct {
    long len;
    data_t *data; // data_t 可通过 typedef 定义成整数/浮点不同类型，便于测试性能
} vec_rec, *vec_ptr;

// 一些后面要用的辅助库方法
int get_vec_element(vec_ptr v, long index, data_t *dest) {
    if (index < 0 || index >= v->len) return 0;
    *dest = v->data[index];
    return 1;
}
long vec_length(vec_ptr v) {
    return v->len;
}

// reduce 操作，IDENT 为初始值，OP 为 reduce 操作，最终结果放在 *dest 中
void combine1(vec_ptr v, data_t *dest) {
    long i;
    
    *dest = IDENT;
    for (i = 0; i < vec_length(v); i++) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

后面以这段代码为例描述优化方法

## 5.4 消除循环的低效率

*代码移动优化*：包括识别要执行多次（例如在循环里）但是计算结果不会改变的计算，因此可以将计算移动到代码前面不会被多次求值的部分。

根据 3.6.7 节的讨论，每次循环迭代时都必须对测试条件求值，而另一方面，向量数组的长度并不会随着循环的进行而改变。因此可以优化：只计算一次向量的长度，然后在测试条件中都使用这个值

```c
void combine2(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);

    *dest = IDENT;
    for (i = 0; i < length; i++) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

优化后性能明显提升

## 5.5 减少过程调用

过程调用会带来开销，而且妨碍大多数形式的程序优化（因为函数可能存在副作用，所以编译器通常不会对函数调用进行优化）。

从 combine2 的代码中可以看出，每次循环迭代都会调用 `get_vec_element` 来获取向量元素，而这个函数每次都会把向量索引 i 与循环边界做比较，明显会造成低效率。在处理任意的数组访问时，边界检查可能是个很有用的特性，但对 combine2 代码的简单分析表明所有的引用都是合法的。

```c
data_t *get_vec_start(vec_ptr v) {
    return v->data;
}
void combine3(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);

    *dest = IDENT;
    for (i = 0; i < length; i++) {
        *dest = *dest OP data[i]; // 没有函数调用，直接访问数组
    }
}
```

然而，性能没有明显提升。说明内循环中的其他操作形成了瓶颈，限制性能超过调用 `get_vec_element`

性能没有明显提升的原因：即使这个转变消除了每次迭代中用于检查向量索引是否在界限内的两个条件语句，但对于这个函数来说，由于这些检测总是确定索引是在界内的，因而对处理器来说分支结果是高度可预测的。

## 5.6 消除不必要的内存引用

我们给出 data_t 为 double，reduce 运算为乘法的 x86-64 代码：

```x86asm
;Inner loop of combine3. data_t = double, OP = *
;dest in %rbx, data+i in %rdx, data+length in %rax
.L17:
    vmovsd (%rbx), %xmm0 ;read product from dest
    vmulsd (%rdx), %xmm0, %xmm0 ;multiply product by data[i]
    vmovsd %xmm0, (%rbx) ;store product at dest
    addq $8, %rdx ;increment data+i
    cmpq %rax, %rdx ;compare to data+length
    jne .L17 ;if !=, goto loop
```

我们看到，指针 dest 的地址存放在 %rbx 中，每次迭代时都需要从内存中读出 dest 的值再写入到内存。这样的读写很浪费，因为每次迭代开始时从 dest 读出的值就是上次迭代最后写入的值。

消除这种不必要的内存读写：

```c
void combine4(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;

    for (i = 0; i < length; i++) {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

程序性能有了显著提高

为什么编译器不自动进行这个优化呢，因为*内存别名使用*的限制。考虑如下函数调用。两个函数执行后 dest 所指位置的值会不同：

```c
// data_t = int, OP = *, IDENT = 1
// v = [2, 3, 5]
combine3(v, get_vec_start(v) + 2);
combine4(v, get_vec_start(v) + 2); // 也就是让向量最后一个元素和存放结果的目标指向同一个内存
```

## 5.7 理解现代处理器

上述的所有优化都不依赖于目标机器的任何特性，这些优化只是简单地降低了过程调用的开销，以及消除了一些重大的“妨碍优化的因素”。随着试图进一步提高性能，必须考虑利用处理器*微体系结构*的优化，也就是处理器用来执行指令的底层系统设计

理解现代处理器的为体系结构：现代处理器的实际操作与通过观察机器级程序所察觉到的大相径庭。在代码级上，看上去似乎是一次执行一条指令，每条指令都包括取指-译码-执行-访存-写回；然而在实际的处理器中，是同时对多条指令进行求值的，这个现象称为*指令级并行*。（但呈现出简单地顺序执行的表象）

程序性能的限制：
- 延迟界限（latency bound）：当一系列操作必须按照严格顺序执行时，因为在下一条指令开始之前这条指令必须结束，代码中的数据相关限制了处理器利用指令级并行的能力
- 吞吐量界限（throughput bound）：处理器功能单元的原始计算能力，这是程序性能的终极限制

### 5.7.1 整体操作

现代微处理器：
- 特点：
  - 超标量：可以在每个时钟周期执行多个操作
  - 乱序：指令执行的顺序不一定要与它们在机器级程序中的顺序一致
- 整个设计有两个部分：
  - 指令控制单元（Instruction Control Unit, ICU）：负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作
  - 执行单元（Execution Unit, EU）：执行这些操作

ICU：
- 从指令高速缓存中读取指令。通常会在当前正在执行的指令很早之前就取指，这样才有足够时间译码并将操作发送给 EU
- 分支：*分支预测*技术，猜测是否选择分支，同时还预测分支的目标地址。使用*投机执行*技术，ICU 开始取出位于它预测的分支会跳到的地方的指令，并译码（甚至在确定分支预测是否正确之前就进行这些操作）
- *取指控制块*：进行分支预测，确定取出哪些指令，然后把指令放到指令高速缓存里
- *指令译码块*：从指令高速缓存中取指，并将他们转换成一组基本操作（复杂指令可能会被译码成多个操作）
- *退役单元*：记录正在进行的处理，并确保它遵守机器程序的顺序语义。包含寄存器文件，控制者这些寄存器状态的更新。
  - 指令译码时，关于指令的信息被放在一个先进先出的队列中。这个信息会一直保持在队列中，直到发生以下两个结果中的一个。
  - 首先，一旦一条指令的操作完成了，而且所有引起这条指令的分支点也都确认为预测正确，那么这条指令就可以*退役*了，所有对程序寄存器的更新都可以被实际执行了。
  - 另一方面，如果引起该指令的某个分支点预测错误，这条指令会被清空，丢弃所有计算出来的结果。从而预测错误就不会改变程序的状态了

EU：
- 接受来自 ICU 的操作，通常每个时钟周期会接受多个。然后将操作分派到一组*功能单元*中，它们执行实际操作
- *加载和存储单元*：执行读写内存操作，通过数据高速缓存来访问内存
- *算术运算单元*：可能有多个
- *分支单元*：确定分支预测是否正确，与前面所述的*取指控制块*通信
  

许多指令信息是在执行单元之间传送的，可以看作*数据转发技术*的更复杂精细版本。控制操作数在执行单元间传送的最常见的机制称为*寄存器重命名*，值可以从一个操作直接转发到另一个操作，而不是写到寄存器文件再读出来（算法描述略）

### 5.7.2 功能单元的性能

刻画功能单元的性能指标：
- 延迟：表示完成运算所需要的总时间
- 发射时间：表示两个连续的同类型的运算之间需要的最小时钟周期数

性能特性：
- 从整数运算到浮点运算，延迟是增加的
- 加法和乘法运算的发射时间都为 1，意思是说在每个时钟周期，处理器都可以开始一条新的这样的运算。这种很短的发射时间是通过*流水线*实现的
- 除法不是完全流水线化的，它的发射时间等于它的延迟，那就意味着在开始一条新运算之前，除法器必须完成整个除法

### 5.7.3 处理器操作的抽象模型

对于形成循环的代码片段，我们可以将访问到的寄存器分为四类：
- 只读：这些寄存器只用作源值，可以作为数据，也可以用来计算内存地址，但是在循环中它们是不会被修改的
- 只写：这些寄存器作为数据传送操作的目的
- 局部：这些寄存器在循环内部被修改和使用，迭代和迭代之间不相关
- 循环：对于循环来说，这些寄存器既作为源值，又作为目的，一次迭代中产生的值会在另一次迭代中用到

循环寄存器之间的操作链决定了限制性能的数据相关

数据流表示中的关键路径提供的只是程序需要周期数的下界，还有一些其他因素会限制性能

## 5.8 循环展开

*循环展开*：是一种程序变换，通过增加每次迭代计算的元素的数量，减少循环的迭代次数。循环展开能够从两个方面改进程序的性能：
- 减少了不直接有助于程序结果的操作的数量，例如循环索引计算和条件分支
- 提供了一些方法，可以进一步变化代码，减少整个计算中关键路径上的操作数量

2*1 循环展开：每次迭代，循环索引 i+2，在一次迭代中，对数组元素 i 和 i+1 进行运算
- 确保第一次循环不会超出数组的界限，对于长度为 n 的数组，循环界限设为 n-1
- 第二次循环处理第一次（可能）剩下的那些元素，保证只有当循环索引 i 满足 i < n-1 时才会执行这个循环，因此最大数组索引 i+1 满足 i+1 < (n-1)+1 = n

k*1 循环展开：
- 第一个循环循环界限 n-k+1
- 第二个循环界限 n

```c
// 2*1 循环展开
void combine5(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    long limit = length-1;
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;

    // combine 2 elements at a time
    for (i = 0; i < limit; i+=2) {
        acc = (acc OP data[i]) OP data[i+1];
    }

    // finish any remaining elements
    for (; i < length; i++) {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

k*1 循环展开不能将性能改进到超过延迟界限，因为对于关键路径而言（这里是循环中的 OP 运算），它虽然减半了迭代次数，但每次迭代中 OP 运算的数量增加了，所以仍然受延迟界限限制。但通过循环展开减少循环索引计算/条件分支等开销，可以使 CPE（需要周期数）无限接近下界，即数据流的关键路径，即延迟界限

优化级别设置为高级别时，很多编译器就可以做到循环展开

## 5.9 提高并行性

以上，程序的性能是受运算单元的延迟限制的。然而，加法/乘法的功能单元是完全流水化的（即每个时钟周期可以开始一个新操作），并且有些操作可以被多个功能单元执行。硬件具有以更高速率执行加法和乘法的能力，但是代码不能利用这些能力。以下要考察打破顺序相关，得到比延迟界限更好性能的方法。

### 5.9.1 多个累积变量

对于一个*可结合和可交换*的合并运算来说，比如说整数加法或乘法，我们可以通过将一组合并运算分割成两个或更多的部分，并在最后合并结果来提高性能

2*2 循环展开：维护两个累积变量，利用了多个功能单元以及它们的流水线能力

```c
// 2*2 循环展开
void combine6(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    long limit = length-1;
    data_t *data = get_vec_start(v);
    data_t acc0 = IDENT;
    data_t acc1 = IDENT;

    // combine 2 elements at a time
    for (i = 0; i < limit; i+=2) {
        acc0 = acc0 OP data[i];
        acc1 = acc1 OP data[i+1];
    }

    // finish any remaining elements
    for (; i < length; i++) {
        acc0 = acc0 OP data[i];
    }
    *dest = acc0 OP acc1;
}
```

k*k 循环展开：将循环展开 k 次，以及并行累积 k 个值。k 值足够大时，程序在所有情况下几乎都能达到吞吐量界限。通常，只有能够保持执行该操作的所有功能单元的流水线都是满的，程序才能达到这个操作的吞吐量界限。对延迟为 L，容量为 C 的操作而言，这就要求循环展开因子 `k >= C*L`

注意，k*k 循环展开要求运算是可结合和可交换的，在本例中，对于整数数据类型，由于补码运算是可交换和可结合的，甚至当溢出时也是如此，因此在所有情况下 combine6 和 combine5 的结果都是相同的。然而，由于浮点乘法和加法不是可结合的，如果产生四舍五入和溢出时，combine6 和 combine5 可能产生不同的结果。

### 5.9.2 重新结合变换

现在来探讨另一种打破顺序相关从而使性能提高到延迟界限之外的方法。

```c
// 2*1a 循环展开
void combine7(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    long limit = length-1;
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;

    // combine 2 elements at a time
    for (i = 0; i < limit; i+=2) {
        acc = acc OP (data[i] OP data[i+1]);
    }

    // finish any remaining elements
    for (; i < length; i++) {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

差别仅在于 `acc = acc OP (data[i] OP data[i+1]);` 这个语句中进行了*重新结合变换*，改变了向量元素与累积值 acc 的合并顺序。这样的变换使得第一个 OP 不需要等待前一次迭代的累积值就可以执行，从而最小可能的 CPE 减小了 2 倍。称之为 `k*1a` 循环展开

同样，对于整数加法和乘法，这些运算是可结合的，重新变换顺序对结果没有影响。对于浮点数，必须再次评估这种重新结合是否有可能严重影响结果，一般对于大多数应用来说，这种差别不重要

## 5.10 优化合并代码的结果小结

现代处理器具有相当的计算能力，但是我们可能需要按非常程式化的方式来编写程序以便将这些能力诱发出来

在一个程序的数据流图表示中，关键路径指明了执行该程序所需时间的一个基本的下界。也就是说，如果程序中有某条数据相关链，这条链上的所有延迟之和等于 T，那么这个程序至少需要 T 个周期才能执行完。

功能单元的吞吐量界限也是程序执行时间的一个下界。也就是说，假设一个程序一共需要 N 个某种运算的计算，而微处理器只有 C 个能执行这个操作的功能单元，并且这些党员的发射时间为 I。那么，这个程序的执行至少需要 N*I/C 个周期

## 5.11 一些限制因素

下面考虑其他一些制约程序在实际机器上性能的因素

### 5.11.1 寄存器溢出

循环并行性的好处受汇编代码描述计算的能力限制。如果我们的并行度 p 超过了可用的寄存器数量，那么编译器会诉诸*溢出*，将某些临时值存放到内存中，通常是在运行时堆栈上分配空间。一旦编译器必须要诉诸寄存器溢出，那么维护多个累积变量的优势就可能消失。

幸运的是，x86-64 有足够多的寄存器，大多数循环在出现寄存器溢出之前就将达到吞吐量限制

### 5.11.2 分支预测和预测错误处罚

一个 C 语言程序员怎么能够保证分支预测处罚不会阻碍程序的效率：
- 不要过分关心可预测的分支
  - 现代处理器中的分支预测逻辑非常善于辨别不同的分支指令的有规律的模式和长期的趋势
- 书写适合用条件传送实现的代码
  - 分支预测只对有规律的模式可行。程序中的许多测试是完全不可预测的，依赖于数据的任意特性，分支预测逻辑会处理得很糟糕
  - 对于本质上无法预测的情况，如果编译器能够产生使用条件数据传送而不是使用条件控制转移的代码，可以极大地提高程序的性能
  - 这不是 C 语言程序员可以直接控制的，但是有些表达条件行为的方法能够更直接地被翻译成条件传送，而不是其他操作。例如：

```c
// 假设给定两个整数数组 a 和 b，对于每个位置 i，我们想将 a[i] 设置为 a[i] 和 b[i] 中较小的那个，而将 b[i] 设置为较大的那个

// 命令式的风格：检查每个位置 i，如果它们的顺序与我们想要的不同，就交换两个元素
void minmax1(long a[], long b[], long n) {
    long i;
    for (i = 0; i < n; i++) {
        if (a[i] > b[i]) {
            long t = a[i];
            a[i] = b[i];
            b[i] = t;
        }
    }
}

// 功能性的风格：计算每个位置 i 的最大值和最小值，然后将这些值分别赋给 a[i] b[i]
// 功能性的风格更容易产生条件传送
void minmax2(long a[], long b[], long n){
    long i;
    for (i = 0; i < n; i++) {
        long min = a[i] < b[i] ? a[i] : b[i];
        long max = a[i] < b[i] ? b[i] : a[i];
        a[i] = min;
        b[i] = max;
    }
}
```

## 5.12 理解内存性能

加载/存储单元通常可以每个时钟周期开始一个操作

### 5.12.1 加载的性能

一个包含加载操作的程序的性能既依赖于流水线的能力，也依赖于加载单元的延迟

### 5.12.2 存储的性能

存储操作并不会影响任何寄存器值，因此，就其本性来说，一系列存储操作不会产生数据相关。只有加载操作会受存储操作结果的影响，因为只有加载操作能从由存储操作写的那个位置读回值

写/读相关：一个内存读的结果依赖于一个最近的内存写。这样会形成数据相关，从而会影响程序的关键路径（可能包括存储/加载数据），影响程序性能

## 5.13 应用：性能提高技术
**
优化程序性能的基本策略：
- 高级设计：为遇到的问题选择适当的算法和数据结构，避免使用那些会渐进的产生糟糕性能的算法或编码技术
- 基本编码原则
  - 消除连续的函数调用。在可能时，将计算移到循环外。考虑有选择地妥协程序的模块性以获得更大的效率
  - 消除不必要的内存引用。引入临时变量来保存中间结果。只有在最后的值计算出来时，才将结果存放到数据或全局变量中。
- 低级优化：结构化代码以利用硬件功能
  - 展开循环，降低开销，并且使得进一步的优化成为可能
  - 通过使用例如多个累积变量和重新结合等技术，找到方法提高指令级并行
  - 用功能性的风格重写条件操作，使得编译采用条件数据传送

## 5.14 确认和消除性能瓶颈

### 5.14.1 程序剖析

程序剖析：运行程序的一个版本，其中插入了工具代码，以确定程序的各个部分需要多少时间

Unix 系统提供了一个剖析程序 GPROF

### 5.14.2 使用剖析程序来指导优化

## 5.15 小结
